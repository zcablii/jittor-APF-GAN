{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jittor as jt\n",
    "from jittor.utils.pytorch_converter import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_code=\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "a = jt.Var(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "VGG19(\n",
      "  (m1): Linear(in_features=12, out_features=16, bias=True)\n",
      "  (m2): Linear(in_features=2, out_features=16, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG19(\n",
       "  (m1): Linear(in_features=12, out_features=16, bias=True)\n",
       "  (m2): None\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from jittor import nn\n",
    "from jittor import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.m1 = nn.Linear(12, 16 * 1 )\n",
    "        exec('self.m%d = nn.Linear(2, 16 * 1 )' % 2)\n",
    "\n",
    "    def execute(self, X):\n",
    "        print(self.m1)\n",
    "        print(self.m2)\n",
    "        return X\n",
    "b = 5\n",
    "exec('a=b+1')\n",
    "print(a)\n",
    "m = VGG19()\n",
    "\n",
    "# getattr(m, 'm2', None)\n",
    "print(m)\n",
    "m.m2 = None\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [1., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 1.]]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input_label = torch.FloatTensor(1,3,2,2).zero_()\n",
    "label_map = torch.tensor([0,0,1,2]).reshape(1,1,2,2).repeat(1,3,1,1)\n",
    "label_map = label_map.type(torch.int64)\n",
    "input_label.scatter_(1, label_map, 1.0)\n",
    "\n",
    "# import jittor as jt\n",
    "# input_label = jt.zeros((1,3,2,2),dtype='float32')\n",
    "# label_map = jt.Var([0,0,1,2]).reshape(1,1,2,2).repeat(1,3,1,1)\n",
    "# input_label.scatter_(1, label_map, jt.array(1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jt.Var([[[[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]]\n",
       "\n",
       "\n",
       " [[[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]]\n",
       "\n",
       "\n",
       " [[[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]]\n",
       "\n",
       "\n",
       " [[[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]]\n",
       "\n",
       "\n",
       " [[[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]\n",
       "\n",
       "  [[0.44444445 0.6666667  0.6666667  ... 0.6666667  0.6666667\n",
       "    0.6666667 ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   ...\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]\n",
       "   [0.6666667  1.         1.         ... 1.         1.\n",
       "    1.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jittor import nn\n",
    "import numpy as np\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" Same architecture as the image discriminator \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        kw = 3\n",
    "        pw = int(np.ceil((kw - 1.0) / 2))\n",
    "        ndf = 12\n",
    "        norm_layer = nn.Identity()\n",
    "        self.layer1 = norm_layer(nn.Conv2d(3, ndf, kw, stride=2, padding=pw))\n",
    "        self.layer2 = norm_layer(nn.Conv2d(ndf * 1, ndf * 2, kw, stride=2, padding=pw))\n",
    "        self.layer3 = norm_layer(nn.Conv2d(ndf * 2, ndf * 4, kw, stride=2, padding=pw))\n",
    "        self.layer4 = norm_layer(nn.Conv2d(ndf * 4, 3, kw, stride=2, padding=pw))\n",
    "      \n",
    "        self.actvn = nn.LeakyReLU(0.2)\n",
    "\n",
    "\n",
    "    def execute(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(self.actvn(x))\n",
    "        x = self.layer3(self.actvn(x))\n",
    "        x = self.layer4(self.actvn(x))\n",
    "        x = self.actvn(x)\n",
    "\n",
    "        return x\n",
    "def downsample(input):\n",
    "    return nn.AvgPool2d(kernel_size=3,\n",
    "                            stride=2, padding=1,\n",
    "                            count_include_pad=False)(input)\n",
    "\n",
    "x = jt.ones([40,32,48,64,],dtype='float32')\n",
    "# encoder = Encoder()\n",
    "# encoder(x)\n",
    "downsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0617 22:19:21.413669 92 cuda_flags.cc:32] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "jt.Var([[[[ 0.02129825 -0.0038312  -0.0038312  -0.0038312 ]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]]\n",
       "\n",
       "  [[-0.00520608 -0.00622648 -0.00622648 -0.00622648]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]]\n",
       "\n",
       "  [[ 0.05037353  0.0503072   0.0503072   0.0503072 ]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]]]\n",
       "\n",
       "\n",
       " [[[ 0.02129825 -0.0038312  -0.0038312  -0.0038312 ]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]]\n",
       "\n",
       "  [[-0.00520608 -0.00622648 -0.00622648 -0.00622648]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]]\n",
       "\n",
       "  [[ 0.05037353  0.0503072   0.0503072   0.0503072 ]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]]]\n",
       "\n",
       "\n",
       " [[[ 0.02129825 -0.0038312  -0.0038312  -0.0038312 ]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]]\n",
       "\n",
       "  [[-0.00520608 -0.00622648 -0.00622648 -0.00622648]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]]\n",
       "\n",
       "  [[ 0.05037353  0.0503072   0.0503072   0.0503072 ]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.02129825 -0.0038312  -0.0038312  -0.0038312 ]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]]\n",
       "\n",
       "  [[-0.00520608 -0.00622648 -0.00622648 -0.00622648]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]]\n",
       "\n",
       "  [[ 0.05037353  0.0503072   0.0503072   0.0503072 ]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]]]\n",
       "\n",
       "\n",
       " [[[ 0.02129825 -0.0038312  -0.0038312  -0.0038312 ]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]]\n",
       "\n",
       "  [[-0.00520608 -0.00622648 -0.00622648 -0.00622648]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]]\n",
       "\n",
       "  [[ 0.05037353  0.0503072   0.0503072   0.0503072 ]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]]]\n",
       "\n",
       "\n",
       " [[[ 0.02129825 -0.0038312  -0.0038312  -0.0038312 ]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]\n",
       "   [ 0.02224597  0.01163984  0.01163984  0.01163984]]\n",
       "\n",
       "  [[-0.00520608 -0.00622648 -0.00622648 -0.00622648]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]\n",
       "   [-0.00379688 -0.00945618 -0.00945618 -0.00945618]]\n",
       "\n",
       "  [[ 0.05037353  0.0503072   0.0503072   0.0503072 ]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]\n",
       "   [ 0.0467836   0.04808769  0.04808769  0.04808769]]]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jt.flags.use_cuda = 1\n",
    "x = jt.ones([40,3,48,64,],dtype='float32')\n",
    "# input_label = torch.FloatTensor(1).fill_(0)\n",
    "# input_label\n",
    "encoder = Encoder()\n",
    "print(x.requires_grad)\n",
    "x = x.detach()\n",
    "\n",
    "with jt.no_grad():\n",
    "    x = encoder(x )\n",
    "    print(x.requires_grad)\n",
    "\n",
    "    with jt.enable_grad():\n",
    "        x = x.detach()\n",
    "        print(x.requires_grad)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6575, -1.2519, -1.5749, -1.3080],\n",
       "          [-0.5012, -0.1550, -0.7069, -1.0683],\n",
       "          [-0.7066, -1.0580, -0.0431, -1.4339],\n",
       "          [-0.6376,  0.0000, -1.2631, -1.6846]],\n",
       "\n",
       "         [[-0.8129,  0.0000, -0.2960, -1.2395],\n",
       "          [-1.6352, -0.4712,  0.0000, -1.4125],\n",
       "          [ 0.0000, -1.8431, -2.6343, -1.7285],\n",
       "          [-1.7550, -1.7589, -0.4913, -2.8552]],\n",
       "\n",
       "         [[-2.5312,  0.0000,  0.0000, -0.9449],\n",
       "          [ 0.0000, -1.6963, -0.3919,  0.0000],\n",
       "          [-0.8014, -0.4813, -2.5086, -1.7754],\n",
       "          [ 0.0000, -1.2154, -0.6087, -2.1910]]],\n",
       "\n",
       "\n",
       "        [[[-0.1517, -1.0859, -0.3034, -0.8581],\n",
       "          [-1.8500,  0.0000, -1.7606,  0.0000],\n",
       "          [-1.0182,  0.0000, -0.1587,  0.0000],\n",
       "          [ 0.0000, -0.5965, -1.3591, -2.5474]],\n",
       "\n",
       "         [[-1.1704, -2.7145, -1.6092, -0.6868],\n",
       "          [ 0.0000, -0.1040, -0.7400, -2.3667],\n",
       "          [-0.6486,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -1.6745, -1.8859, -1.4478]],\n",
       "\n",
       "         [[-0.3715, -0.4300, -0.0944, -2.0048],\n",
       "          [-0.6310, -1.9703,  0.0000, -0.6216],\n",
       "          [ 0.0000, -1.0734, -1.8595, -0.3697],\n",
       "          [-2.0896, -2.5885, -0.0449, -1.4908]]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Tensor = torch.FloatTensor\n",
    "def get_zero_tensor(input):\n",
    "        zero_tensor = Tensor(1).fill_(0)\n",
    "        zero_tensor.requires_grad_(False)\n",
    "        return zero_tensor.expand_as(input)\n",
    "\n",
    "\n",
    "inp = torch.randn(2,3,4,4)\n",
    "inp.shape\n",
    "inp2 = jt.randn(2,3,4,4)\n",
    "inp2.shape\n",
    "torch.min(-inp-1,get_zero_tensor(inp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'jittor_core.Var' object has no attribute 'get_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m get_zero_tensor(inp2)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m a \u001b[39m=\u001b[39m jt\u001b[39m.\u001b[39mminimum(inp2,get_zero_tensor(inp2))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m a\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39;49mget_device()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'jittor_core.Var' object has no attribute 'get_device'"
     ]
    }
   ],
   "source": [
    "Tensor = jt.float16\n",
    "def get_zero_tensor(input):\n",
    "        zero_tensor = Tensor(0)\n",
    "        zero_tensor.stop_grad()\n",
    "        return zero_tensor.expand_as(input)\n",
    "get_zero_tensor(inp2)\n",
    "a = jt.minimum(inp2,get_zero_tensor(inp2))\n",
    "a.mean().get_device() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0618 14:28:25.505722 24 cuda_flags.cc:32] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'leaky_relu' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000009vscode-remote?line=48'>49</a>\u001b[0m \u001b[39m# y.shape, type(y), y.dtype,y\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000009vscode-remote?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m encd\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000009vscode-remote?line=50'>51</a>\u001b[0m     \u001b[39mprint\u001b[39m(m\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/jittor/lib/python3.8/site-packages/jittor/__init__.py:1286\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m-> 1286\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'leaky_relu' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "\n",
    "import jittor as jt\n",
    "from jittor import init\n",
    "from jittor import nn\n",
    "import numpy as np\n",
    "from models.networks.base_network import BaseNetwork\n",
    "from models.networks.normalization import get_nonspade_norm_layer\n",
    "jt.flags.use_cuda = 1\n",
    "# jt.flags.auto_mixed_precision_level = 5\n",
    "\n",
    "\n",
    "class ConvEncoder(BaseNetwork):\n",
    "    \"\"\" Same architecture as the image discriminator \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        kw = 3\n",
    "        pw = int(np.ceil((kw - 1.0) / 2))\n",
    "        ndf = 64\n",
    "        norm_layer = nn.Identity()\n",
    "        self.layer1 = norm_layer(nn.Conv2d(29, ndf, kw, stride=2, padding=pw))\n",
    "        self.layer2 = norm_layer(nn.Conv2d(ndf * 1, ndf * 2, kw, stride=2, padding=pw))\n",
    "        self.layer3 = norm_layer(nn.Conv2d(ndf * 2, ndf * 4, kw, stride=2, padding=pw))\n",
    "        self.layer4 = norm_layer(nn.Conv2d(ndf * 4, ndf * 8, kw, stride=2, padding=pw))\n",
    "        self.layer5 = norm_layer(nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw))\n",
    "        self.layer6 = norm_layer(nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw))\n",
    "\n",
    "            # re-load layer1 and layer6\n",
    "        self.actvn = nn.LeakyReLU(0.2, False)\n",
    "   \n",
    "\n",
    "    def execute(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer3(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer4(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer5(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer6(nn.leaky_relu(x,0.2))\n",
    "        x = nn.leaky_relu(x,0.2)\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "x = jt.ones((20,29,384,512))\n",
    "x = jt.float16(x)\n",
    "encd = ConvEncoder()\n",
    "with jt.flag_scope(auto_mixed_precision_level=0):\n",
    "    y = encd(x)\n",
    "# y.shape, type(y), y.dtype,y\n",
    "for m in encd.children():\n",
    "    print(m.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jt.Var([[[[-0.00203571 -0.00259454 -0.00259454 ... -0.00259454 -0.00259454\n",
       "    -0.00259454]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]]\n",
       "\n",
       "  [[-0.00142581 -0.00171824 -0.00171824 ... -0.00171824 -0.00171824\n",
       "    -0.00171824]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]]\n",
       "\n",
       "  [[-0.00036775  0.00440716  0.00440716 ...  0.00440716  0.00440716\n",
       "     0.00440716]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00330639  0.00593036  0.00593036 ...  0.00593036  0.00593036\n",
       "     0.00593036]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]]\n",
       "\n",
       "  [[ 0.00403486 -0.0012738  -0.0012738  ... -0.0012738  -0.0012738\n",
       "    -0.0012738 ]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]]\n",
       "\n",
       "  [[ 0.01497895  0.01927587  0.01927587 ...  0.01927587  0.01927587\n",
       "     0.01927587]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]]]\n",
       "\n",
       "\n",
       " [[[-0.00203571 -0.00259454 -0.00259454 ... -0.00259454 -0.00259454\n",
       "    -0.00259454]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]]\n",
       "\n",
       "  [[-0.00142581 -0.00171824 -0.00171824 ... -0.00171824 -0.00171824\n",
       "    -0.00171824]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]]\n",
       "\n",
       "  [[-0.00036775  0.00440716  0.00440716 ...  0.00440716  0.00440716\n",
       "     0.00440716]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00330639  0.00593036  0.00593036 ...  0.00593036  0.00593036\n",
       "     0.00593036]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]]\n",
       "\n",
       "  [[ 0.00403486 -0.0012738  -0.0012738  ... -0.0012738  -0.0012738\n",
       "    -0.0012738 ]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]]\n",
       "\n",
       "  [[ 0.01497895  0.01927587  0.01927587 ...  0.01927587  0.01927587\n",
       "     0.01927587]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]]]\n",
       "\n",
       "\n",
       " [[[-0.00203571 -0.00259454 -0.00259454 ... -0.00259454 -0.00259454\n",
       "    -0.00259454]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]]\n",
       "\n",
       "  [[-0.00142581 -0.00171824 -0.00171824 ... -0.00171824 -0.00171824\n",
       "    -0.00171824]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]]\n",
       "\n",
       "  [[-0.00036775  0.00440716  0.00440716 ...  0.00440716  0.00440716\n",
       "     0.00440716]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00330639  0.00593036  0.00593036 ...  0.00593036  0.00593036\n",
       "     0.00593036]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]]\n",
       "\n",
       "  [[ 0.00403486 -0.0012738  -0.0012738  ... -0.0012738  -0.0012738\n",
       "    -0.0012738 ]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]]\n",
       "\n",
       "  [[ 0.01497895  0.01927587  0.01927587 ...  0.01927587  0.01927587\n",
       "     0.01927587]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-0.00203571 -0.00259454 -0.00259454 ... -0.00259454 -0.00259454\n",
       "    -0.00259454]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]]\n",
       "\n",
       "  [[-0.00142581 -0.00171824 -0.00171824 ... -0.00171824 -0.00171824\n",
       "    -0.00171824]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]]\n",
       "\n",
       "  [[-0.00036775  0.00440716  0.00440716 ...  0.00440716  0.00440716\n",
       "     0.00440716]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00330639  0.00593036  0.00593036 ...  0.00593036  0.00593036\n",
       "     0.00593036]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]]\n",
       "\n",
       "  [[ 0.00403486 -0.0012738  -0.0012738  ... -0.0012738  -0.0012738\n",
       "    -0.0012738 ]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]]\n",
       "\n",
       "  [[ 0.01497895  0.01927587  0.01927587 ...  0.01927587  0.01927587\n",
       "     0.01927587]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]]]\n",
       "\n",
       "\n",
       " [[[-0.00203571 -0.00259454 -0.00259454 ... -0.00259454 -0.00259454\n",
       "    -0.00259454]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]]\n",
       "\n",
       "  [[-0.00142581 -0.00171824 -0.00171824 ... -0.00171824 -0.00171824\n",
       "    -0.00171824]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]]\n",
       "\n",
       "  [[-0.00036775  0.00440716  0.00440716 ...  0.00440716  0.00440716\n",
       "     0.00440716]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00330639  0.00593036  0.00593036 ...  0.00593036  0.00593036\n",
       "     0.00593036]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]]\n",
       "\n",
       "  [[ 0.00403486 -0.0012738  -0.0012738  ... -0.0012738  -0.0012738\n",
       "    -0.0012738 ]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]]\n",
       "\n",
       "  [[ 0.01497895  0.01927587  0.01927587 ...  0.01927587  0.01927587\n",
       "     0.01927587]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]]]\n",
       "\n",
       "\n",
       " [[[-0.00203571 -0.00259454 -0.00259454 ... -0.00259454 -0.00259454\n",
       "    -0.00259454]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]\n",
       "   [-0.00163781 -0.00111778 -0.00111778 ... -0.00111778 -0.00111778\n",
       "    -0.00111778]]\n",
       "\n",
       "  [[-0.00142581 -0.00171824 -0.00171824 ... -0.00171824 -0.00171824\n",
       "    -0.00171824]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]\n",
       "   [-0.001165   -0.00018073 -0.00018073 ... -0.00018073 -0.00018073\n",
       "    -0.00018073]]\n",
       "\n",
       "  [[-0.00036775  0.00440716  0.00440716 ...  0.00440716  0.00440716\n",
       "     0.00440716]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]\n",
       "   [-0.00113051  0.000148    0.000148   ...  0.000148    0.000148\n",
       "     0.000148  ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00330639  0.00593036  0.00593036 ...  0.00593036  0.00593036\n",
       "     0.00593036]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]\n",
       "   [ 0.00571162  0.00823407  0.00823407 ...  0.00823407  0.00823407\n",
       "     0.00823407]]\n",
       "\n",
       "  [[ 0.00403486 -0.0012738  -0.0012738  ... -0.0012738  -0.0012738\n",
       "    -0.0012738 ]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]\n",
       "   [ 0.0037247  -0.00200344 -0.00200344 ... -0.00200344 -0.00200344\n",
       "    -0.00200344]]\n",
       "\n",
       "  [[ 0.01497895  0.01927587  0.01927587 ...  0.01927587  0.01927587\n",
       "     0.01927587]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]\n",
       "   [ 0.0132808   0.00757913  0.00757913 ...  0.00757913  0.00757913\n",
       "     0.00757913]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvEncoder_more(BaseNetwork):\n",
    "    \"\"\" Same architecture as the image discriminator \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        kw = 3\n",
    "        pw = int(np.ceil((kw - 1.0) / 2))\n",
    "        ndf = 64\n",
    "        norm_layer = nn.Identity()\n",
    "        self.layer1 = norm_layer(nn.Conv2d(3, ndf, kw, stride=2, padding=pw))\n",
    "        self.layer2 = norm_layer(nn.Conv2d(ndf * 1, ndf * 2, kw, stride=2, padding=pw))\n",
    "        self.layer3 = norm_layer(nn.Conv2d(ndf * 2, ndf * 4, kw, stride=2, padding=pw))\n",
    "        self.layer4 = norm_layer(nn.Conv2d(ndf * 4, ndf * 8, kw, stride=2, padding=pw))\n",
    "        self.layer5 = norm_layer(nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw))\n",
    "        self.layer6 = norm_layer(nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw))\n",
    "        self.layer7 = norm_layer(nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw))\n",
    "\n",
    "            # re-load layer1 and layer6\n",
    "        self.layer1 = norm_layer(nn.Conv2d(29, ndf, kw, stride=2, padding=pw))\n",
    "        self.layer6 = norm_layer(nn.Conv2d(ndf * 8, ndf * 16, kw, stride=2, padding=pw))\n",
    "\n",
    "        self.so = s0 = 4\n",
    "        self.fc_mu = nn.Linear(ndf * 8 * s0 * s0, 256)\n",
    "        self.fc_var = nn.Linear(ndf * 8 * s0 * s0, 256)\n",
    "\n",
    "        self.actvn = nn.LeakyReLU(0.2, False)\n",
    "   \n",
    "\n",
    "    def execute(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer3(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer4(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer5(nn.leaky_relu(x,0.2))\n",
    "        x = self.layer6(nn.leaky_relu(x,0.2))\n",
    "        x = nn.leaky_relu(x,0.2)\n",
    "\n",
    "        return x\n",
    "encd2 = ConvEncoder_more()\n",
    "encd2.load_state_dict(encd.state_dict())\n",
    "encd2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m jt\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mauto_mixed_precision_level \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m jt\u001b[39m.\u001b[39mfloat32(x)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/lyx/jittor-Torile-GanVit/SPADE_jittor/convertion.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m x\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "jt.flags.auto_mixed_precision_level = 5\n",
    "x = jt.float32(x)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('jittor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "866ebf4ae3c95aeda7f8f2d5ed834225867c604b4a8f9bce3a4957565c899f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
